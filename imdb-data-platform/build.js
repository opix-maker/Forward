import fs from 'fs/promises';
import { constants as fsConstants } from 'fs';
import path from 'path';
import fetch from 'node-fetch';
import { pipeline } from 'stream/promises';
import { createWriteStream, createReadStream } from 'fs';
import zlib from 'zlib';
import readline from 'readline';
import { findByImdbId, getTmdbDetails } from './src/utils/tmdb_api.js'; 
import { analyzeAndTagItem } from './src/core/analyzer.js';

// --- ÂÖ®Â±ÄÈÖçÁΩÆ ---
const MAX_CONCURRENT_ENRICHMENTS = 10; // Èôç‰ΩéÂπ∂Âèë‰ª•Êñπ‰æøÊü•ÁúãÊó•Âøó
const MAX_CONCURRENT_FILE_IO = 64;     

// --- ÁºìÂ≠òËÆæÁΩÆ ---
const MAX_DOWNLOAD_AGE_MS = 20 * 60 * 60 * 1000; 
const DATA_LAKE_CACHE_AGE_MS = 20 * 60 * 60 * 1000;

// --- Êï∞ÊçÆËøáÊª§ÈòàÂÄº ---
const MIN_VOTES = 1000;   
const MIN_YEAR = 1990;     
const MIN_RATING = 6.0;    
const ALLOWED_TITLE_TYPES = new Set(['movie', 'tvSeries', 'tvMiniSeries', 'tvMovie']);
const CURRENT_YEAR = new Date().getFullYear();
const RECENT_YEAR_THRESHOLD = CURRENT_YEAR - 1;

// --- ÂàÜÈ°µÂíåÊéíÂ∫è ---
const ITEMS_PER_PAGE = 30;
const SORT_CONFIG = { 
    'hs': 'hotness_score',
    'r': 'vote_average',
    'd': 'default_order'
};

// --- Êñá‰ª∂Ë∑ØÂæÑ ---
const DATASET_DIR = './datasets';
const TEMP_DIR = './temp';
const FINAL_OUTPUT_DIR = './dist';
const DATA_LAKE_FILE = path.join(TEMP_DIR, 'datalake.jsonl');

const DATASETS = {
    basics: { url: 'https://datasets.imdbws.com/title.basics.tsv.gz', local: 'title.basics.tsv' },
    ratings: { url: 'https://datasets.imdbws.com/title.ratings.tsv.gz', local: 'title.ratings.tsv' },
    akas: { url: 'https://datasets.imdbws.com/title.akas.tsv.gz', local: 'title.akas.tsv' },
};

// --- ÂàÜÁâáÁª¥Â∫¶ÂÆö‰πâ ---
const REGIONS = ['all', 'region:chinese', 'region:us-eu', 'region:east-asia', 'country:cn', 'country:hk', 'country:tw', 'country:us', 'country:gb', 'country:jp', 'country:kr', 'country:fr', 'country:de', 'country:ca', 'country:au'];
const GENRES_AND_THEMES = ['genre:Áà±ÊÉÖ', 'genre:ÂÜíÈô©', 'genre:ÊÇ¨Áñë', 'genre:ÊÉäÊÇö', 'genre:ÊÅêÊÄñ', 'genre:ÁßëÂπª', 'genre:Â•áÂπª', 'genre:Âä®‰Ωú', 'genre:ÂñúÂâß', 'genre:ÂâßÊÉÖ', 'genre:ÂéÜÂè≤', 'genre:Êàò‰∫â', 'genre:ÁäØÁΩ™', 'theme:whodunit', 'theme:spy', 'theme:courtroom', 'theme:slice-of-life', 'theme:wuxia', 'theme:superhero', 'theme:cyberpunk', 'theme:space-opera', 'theme:time-travel', 'theme:post-apocalyptic', 'theme:mecha', 'theme:zombie', 'theme:monster', 'theme:ghost', 'theme:magic', 'theme:gangster', 'theme:film-noir', 'theme:serial-killer', 'theme:xianxia', 'theme:kaiju', 'theme:isekai'];
const YEARS = Array.from({length: CURRENT_YEAR - 1990 + 1}, (_, i) => 1990 + i).reverse();


// === ËæÖÂä©ÂáΩÊï∞ (‰øùÊåÅ‰∏çÂèò) ===
async function isDataLakeCacheValid(filePath, maxAgeMs) { try { const stats = await fs.stat(filePath); const ageMs = Date.now() - stats.mtimeMs; console.log(`  > Data Lake file found. Age: ${(ageMs / 1000 / 60).toFixed(1)} minutes.`); return ageMs < maxAgeMs; } catch (e) { if (e.code === 'ENOENT') { console.log('  > Data Lake file not found.'); } else { console.error('  > Error checking Data Lake cache:', e.message); } return false; } }
async function downloadAndUnzipWithCache(url, localPath, maxAgeMs) { const dir = path.dirname(localPath); await fs.mkdir(dir, { recursive: true }); try { const stats = await fs.stat(localPath); if (Date.now() - stats.mtimeMs < maxAgeMs) { console.log(`  ‚úÖ Cache hit for ${path.basename(localPath)}.`); return; } } catch (e) { /* no cache */ } console.log(`  ‚è≥ Downloading from: ${url}`); const response = await fetch(url, { headers: { 'User-Agent': 'IMDb-Builder/1.0' } }); if (!response.ok) throw new Error(`Failed to download ${url}: ${response.statusText}`); if (!response.body) throw new Error(`Response body is null for ${url}`); const gunzip = zlib.createGunzip(); const destination = createWriteStream(localPath); try { await pipeline(response.body, gunzip, destination); console.log(`  ‚úÖ Download and unzip complete for ${path.basename(localPath)}.`); } catch (error) { console.error(`  ‚ùå Error during download/unzip for ${url}:`, error); await fs.unlink(localPath).catch(() => {}); throw error; } }
async function processTsvByLine(filePath, processor) { const fileStream = createReadStream(filePath); const rl = readline.createInterface({ input: fileStream, crlfDelay: Infinity }); let isFirstLine = true; let count = 0; for await (const line of rl) { if (isFirstLine) { isFirstLine = false; continue; } if (line && line.includes('\t')) { processor(line); count++; if (count % 2000000 === 0) { console.log(`    ... Processed ${count} lines...`); } } } console.log(`    ‚úÖ Processed total ${count} lines from ${path.basename(filePath)}.`); }
async function processInParallel(items, concurrency, task) { const queue = [...items]; let processedCount = 0; const totalCount = items.length; let totalFiles = 0; const worker = async () => { while (queue.length > 0) { const item = queue.shift(); if (item) { const result = await task(item); processedCount++; if (typeof result === 'number') { totalFiles += result; } const updateFrequency = 500; if (processedCount % updateFrequency === 0 || processedCount === totalCount) { let progressLine = `  ... Progress: ${processedCount} / ${totalCount} (${(processedCount / totalCount * 100).toFixed(1)}%)`; if (totalFiles > 0) { progressLine += ` (Files generated: ${totalFiles})`; } console.log(progressLine); } } } }; const workers = Array(Math.min(concurrency, items.length)).fill(null).map(() => worker()); await Promise.all(workers); return totalFiles; }


// === Èò∂ÊÆµ 1-3: ÊûÑÂª∫Êï∞ÊçÆÊπñ ===
let idPool = new Map();
let akasIndex = new Map();
async function buildDataLake() {
    console.log('\n--- PHASE 1: Building Ratings Index & Downloading Data ---');
    const ratingsIndex = new Map();
    const ratingsPath = path.join(DATASET_DIR, DATASETS.ratings.local);
    await downloadAndUnzipWithCache(DATASETS.ratings.url, ratingsPath, MAX_DOWNLOAD_AGE_MS);
    await processTsvByLine(ratingsPath, (line) => { const parts = line.split('\t'); const votes = parseInt(parts[2], 10) || 0; const rating = parseFloat(parts[1]) || 0; if (votes >= MIN_VOTES && rating >= MIN_RATING) { ratingsIndex.set(parts[0], { rating, votes }); } });
    console.log(`  ‚úÖ Ratings index built. Total items: ${ratingsIndex.size}.`);
    console.log(`\n--- PHASE 2: Filtering Basics & Building ID Pool ---`);
    idPool.clear();
    const basicsPath = path.join(DATASET_DIR, DATASETS.basics.local);
    await downloadAndUnzipWithCache(DATASETS.basics.url, basicsPath, MAX_DOWNLOAD_AGE_MS);
    await processTsvByLine(basicsPath, (line) => { const parts = line.split('\t'); const tconst = parts[0]; const year = parseInt(parts[5], 10); const genres = parts[8]; if (!tconst.startsWith('tt') || parts[4] === '1' || !ALLOWED_TITLE_TYPES.has(parts[1]) || isNaN(year) || year < MIN_YEAR || !ratingsIndex.has(tconst)) { return; } idPool.set(tconst, genres); });
    console.log(`  ‚úÖ Filtered ID pool built. Total items: ${idPool.size}.`);
    console.log(`\n--- PHASE 2.5: Building AKAS Region/Language Index ---`);
    akasIndex.clear();
    const akasPath = path.join(DATASET_DIR, DATASETS.akas.local);
    await downloadAndUnzipWithCache(DATASETS.akas.url, akasPath, MAX_DOWNLOAD_AGE_MS);
    await processTsvByLine(akasPath, (line) => { const parts = line.split('\t'); const tconst = parts[0]; if (idPool.has(tconst)) { const region = parts[3] && parts[3] !== '\\N' ? parts[3].toLowerCase() : null; const language = parts[4] && parts[4] !== '\\N' ? parts[4].toLowerCase() : null; if (!akasIndex.has(tconst)) { akasIndex.set(tconst, { regions: new Set(), languages: new Set() }); } const entry = akasIndex.get(tconst); if (region) entry.regions.add(region); if (language) entry.languages.add(language); } });
    console.log(`  ‚úÖ AKAS index built. Items processed: ${akasIndex.size}.`);
    
    console.log(`\n--- PHASE 3: Enriching Data via TMDB API (DIAGNOSTIC MODE) ---`);
    await fs.rm(TEMP_DIR, { recursive: true, force: true }).catch(() => {}); 
    await fs.mkdir(TEMP_DIR, { recursive: true });
    const writeStream = createWriteStream(DATA_LAKE_FILE, { flags: 'a' });
    
    const enrichmentTask = async (imdbId) => {
         try {
            const info = await findByImdbId(imdbId);
            if (!info || !info.id || !info.media_type) return;

            const details = await getTmdbDetails(info.id, info.media_type);
            if (details) {
                // =============== DIAGNOSTIC LOGGING START ===============
                console.log(`\n\n==================== [RAW TMDB DATA for ${imdbId}] ====================`);
                console.log(JSON.stringify(details, null, 2));
                console.log(`==================== [END RAW TMDB DATA for ${imdbId}] ====================\n`);
                // =============== DIAGNOSTIC LOGGING END ===============

                const imdbAkasInfo = akasIndex.get(imdbId) || { regions: new Set(), languages: new Set() };
                const imdbGenresString = idPool.get(imdbId);
                const analyzedItem = analyzeAndTagItem(details, imdbAkasInfo, imdbGenresString);
                
                if (analyzedItem) {
                    writeStream.write(JSON.stringify(analyzedItem) + '\n'); 
                }
            }
        } catch (error) {
            console.warn(`  Skipping ID ${imdbId} due to enrichment error: ${error.message}`);
        }
    };
    
    // ================== DIAGNOSTIC LIMIT ==================
    // Âè™Â§ÑÁêÜÂâç 10 ‰∏™È°πÁõÆ‰ª•Âø´ÈÄüËé∑ÂèñÊó•Âøó
    const itemsToProcess = Array.from(idPool.keys()).slice(0, 10);
    console.log(`[DIAGNOSTIC MODE] Processing only the first ${itemsToProcess.length} items.`);
    // ======================================================

    await processInParallel(itemsToProcess, MAX_CONCURRENT_ENRICHMENTS, enrichmentTask);
    
    await new Promise(resolve => writeStream.end(resolve));
    console.log(`  ‚úÖ Data Lake built with diagnostic data.`);
}



// === Èò∂ÊÆµ 4: ÂàÜÁâá„ÄÅÊéíÂ∫èÂíåÂàÜÈ°µ (‰øùÊåÅ‰∏çÂèò) ===
function minifyItem(item) { return { id: item.id, p: item.poster_path, b: item.backdrop_path, t: item.title, r: item.vote_average, y: item.release_year, rd: item.release_date, hs: parseFloat(item.hotness_score.toFixed(3)), d: parseFloat(item.default_order.toFixed(3)), mt: item.mediaType, o: item.overview }; }
const dirCreationPromises = new Map();
async function ensureDir(dir) { if (dirCreationPromises.has(dir)) { return dirCreationPromises.get(dir); } const promise = fs.mkdir(dir, { recursive: true }).catch(err => { if (err.code !== 'EEXIST') throw err; }); dirCreationPromises.set(dir, promise); return promise; }
async function processAndWriteSortedPaginatedShards(task) { const { basePath, data } = task; if (data.length === 0) return 0; const currentShardWritePromises = []; const metadata = { total_items: data.length, items_per_page: ITEMS_PER_PAGE, pages: {} }; for (const [sortPrefix, internalKey] of Object.entries(SORT_CONFIG)) { const sortedData = [...data].sort((a, b) => (b[internalKey] || 0) - (a[internalKey] || 0)); const numPages = Math.ceil(sortedData.length / ITEMS_PER_PAGE); metadata.pages[sortPrefix] = numPages; for (let page = 1; page <= numPages; page++) { const start = (page - 1) * ITEMS_PER_PAGE; const pageData = sortedData.slice(start, start + ITEMS_PER_PAGE); const minifiedPageData = pageData.map(minifyItem); const finalPath = path.join(FINAL_OUTPUT_DIR, basePath, `by_${sortPrefix}`, `page_${page}.json`); const dir = path.dirname(finalPath); const writePromise = ensureDir(dir).then(() => fs.writeFile(finalPath, JSON.stringify(minifiedPageData))); currentShardWritePromises.push(writePromise); } } const metaPath = path.join(FINAL_OUTPUT_DIR, basePath, 'meta.json'); const metaDir = path.dirname(metaPath); const metaWritePromise = ensureDir(metaDir).then(() => fs.writeFile(metaPath, JSON.stringify(metadata))); currentShardWritePromises.push(metaWritePromise); await Promise.all(currentShardWritePromises); return currentShardWritePromises.length; }
async function shardDatabase() {
    console.log(`\n--- PHASE 4: Sharding, Sorting, Paginating & Writing Files (I/O Concurrency: ${MAX_CONCURRENT_FILE_IO}) ---`);
    await fs.rm(FINAL_OUTPUT_DIR, { recursive: true, force: true }).catch(() => {});
    await fs.mkdir(FINAL_OUTPUT_DIR, { recursive: true });
    dirCreationPromises.clear();
    console.log('  Loading data lake from disk...');
    const database = [];
    try { await fs.access(DATA_LAKE_FILE, fsConstants.R_OK); } catch (e) { console.error(`\n‚ùå FATAL ERROR: Data Lake file ${DATA_LAKE_FILE} not found. Cannot proceed.`); throw new Error("Data Lake file missing."); }
    const rl = readline.createInterface({ input: createReadStream(DATA_LAKE_FILE), crlfDelay: Infinity });
    for await (const line of rl) { if (line.trim()) { database.push(JSON.parse(line)); } }
    console.log(`  ‚úÖ Loaded ${database.length} items from data lake.`);
    if (database.length === 0) { console.log('  ‚ö†Ô∏è No items in database to process. Exiting Phase 4.'); return; }
    console.log('  Calculating hotness and default scores...');
    const validForStats = database.filter(i => i.vote_count > 100);
    const totalRating = validForStats.reduce((sum, item) => sum + (item.vote_average || 0), 0);
    const GLOBAL_AVERAGE_RATING = validForStats.length > 0 ? totalRating / validForStats.length : 6.8;
    const sortedVotes = validForStats.map(i => i.vote_count).sort((a,b) => a - b);
    const MINIMUM_VOTES_THRESHOLD = sortedVotes[Math.floor(sortedVotes.length * 0.75)] || 500;
    console.log(`  ‚ÑπÔ∏è Global Stats: AvgRating=${GLOBAL_AVERAGE_RATING.toFixed(2)}, MinVotesThreshold=${MINIMUM_VOTES_THRESHOLD}`);
    database.forEach(item => { const pop = item.popularity || 0; const year = item.release_year || 1970; const R = item.vote_average || 0; const v = item.vote_count || 0; const yearDiff = Math.max(0, CURRENT_YEAR - year); const timeDecay = 1 / Math.sqrt(yearDiff + 2); const bayesianRating = (v / (v + MINIMUM_VOTES_THRESHOLD)) * R + (MINIMUM_VOTES_THRESHOLD / (v + MINIMUM_VOTES_THRESHOLD)) * GLOBAL_AVERAGE_RATING; item.hotness_score = Math.log10(pop + 1) * timeDecay * bayesianRating; item.default_order = pop; });
    console.log('  Collecting all shard definitions...');
    const shardTasksDefinitions = []; const contentTypes = ['all', 'movie', 'tv', 'anime']; const definedRegions = REGIONS;
    const filterData = (baseData, type, region) => { let filtered = baseData; if (type !== 'all') { filtered = filtered.filter(i => i.mediaType === type); } if (region !== 'all') { filtered = filtered.filter(i => i.semantic_tags.includes(region)); } return filtered; };
    const addShardDefinition = (pathName, data) => { shardTasksDefinitions.push({ basePath: pathName, data: data }); };
    const recentHotBase = database.filter(i => i.release_year >= RECENT_YEAR_THRESHOLD);
    for (const type of contentTypes) { for (const region of definedRegions) { const data = filterData(recentHotBase, type, region); addShardDefinition(`hot/${type}/${region.replace(':', '_')}`, data); } }
    const allCategories = ['all', ...GENRES_AND_THEMES]; 
    for (const tag of allCategories) { const tagBaseData = (tag === 'all') ? database : database.filter(i => i.semantic_tags.includes(tag)); for (const type of contentTypes) { for (const region of definedRegions) { const data = filterData(tagBaseData, type, region); addShardDefinition(`tag/${tag.replace(':', '_')}/${type}/${region.replace(':', '_')}`, data); } } }
    const allYears = ['all', ...YEARS]; 
    for (const year of allYears) { const yearBaseData = (year === 'all') ? database : database.filter(i => i.release_year === year); for (const type of contentTypes) { for (const region of definedRegions) { const data = filterData(yearBaseData, type, region); addShardDefinition(`year/${year}/${type}/${region.replace(':', '_')}`, data); } } }
    const directTypes = [{ name: 'movies', mediaType: 'movie' }, { name: 'tvseries', mediaType: 'tv' }, { name: 'anime', mediaType: 'anime' }];
    for (const type of directTypes) { let baseData = database.filter(i => i.mediaType === type.mediaType); for (const region of definedRegions) { let data = (region === 'all') ? baseData : baseData.filter(i => i.semantic_tags.includes(region)); addShardDefinition(`${type.name}/${region.replace(':', '_')}`, data); } }
    console.log(`  Processing ${shardTasksDefinitions.length} shards in parallel...`);
    const totalFiles = await processInParallel(shardTasksDefinitions, MAX_CONCURRENT_FILE_IO, processAndWriteSortedPaginatedShards);
    await fs.writeFile(path.join(FINAL_OUTPUT_DIR, 'manifest.json'), JSON.stringify({ buildTimestamp: new Date().toISOString(), regions: REGIONS, tags: GENRES_AND_THEMES, years: YEARS, itemsPerPage: ITEMS_PER_PAGE, sortOptions: Object.keys(SORT_CONFIG), contentTypes: contentTypes, isPaginated: true }));
    console.log(`  ‚úÖ Phase 4 complete. Total shards processed: ${shardTasksDefinitions.length}. Total files generated: ${totalFiles}.`);
}


// === ‰∏ªÊâßË°åÂÖ•Âè£ ===
async function main() {
    console.log('üé¨ Starting IMDb Discovery Engine Build Process (DIAGNOSTIC MODE)...');
    const startTime = Date.now();
    try {
        console.log('\nüîç Checking Data Lake cache...');
        const cacheValid = await isDataLakeCacheValid(DATA_LAKE_FILE, DATA_LAKE_CACHE_AGE_MS);
        if (cacheValid) {
            console.log('‚úÖ Cache hit! Using existing Data Lake. Skipping Phases 1-3.');
        } else {
            console.log('‚ùå Cache miss or stale. Starting full build (Phases 1-3)...');
            await buildDataLake();
        }
        await shardDatabase(); 
        const duration = (Date.now() - startTime) / 1000;
        console.log(`\nüéâ DIAGNOSTIC RUN COMPLETE! üéâ`);
        console.log(`Total time: ${duration.toFixed(2)} seconds.`);
    } catch (error) {
        console.error('\n‚ùå FATAL ERROR during build process:', error.stack || error);
        process.exit(1); 
    } finally {
        console.log(`\nBuild finished. Cache file preserved at ${DATA_LAKE_FILE}`);
    }
}

main();
